{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-26T14:53:37.054714Z",
     "iopub.status.busy": "2025-07-26T14:53:37.054309Z",
     "iopub.status.idle": "2025-07-26T14:53:38.710484Z",
     "shell.execute_reply": "2025-07-26T14:53:38.710015Z"
    }
   },
   "outputs": [
    {
     "ename": "ArgumentError",
     "evalue": "ArgumentError: Package matplotlib not found in current path.\n- Run `import Pkg; Pkg.add(\"matplotlib\")` to install the matplotlib package.",
     "output_type": "error",
     "traceback": [
      "ArgumentError: Package matplotlib not found in current path.\n",
      "- Run `import Pkg; Pkg.add(\"matplotlib\")` to install the matplotlib package.\n",
      "\n",
      "Stacktrace:\n",
      "  [1] macro expansion\n",
      "    @ ./loading.jl:1630 [inlined]\n",
      "  [2] macro expansion\n",
      "    @ ./lock.jl:267 [inlined]\n",
      "  [3] require(into::Module, mod::Symbol)\n",
      "    @ Base ./loading.jl:1611\n",
      "  [4] eval\n",
      "    @ ./boot.jl:370 [inlined]\n",
      "  [5] include_string(mapexpr::typeof(REPL.softscope), mod::Module, code::String, filename::String)\n",
      "    @ Base ./loading.jl:1903\n",
      "  [6] #invokelatest#2\n",
      "    @ ./essentials.jl:819 [inlined]\n",
      "  [7] invokelatest\n",
      "    @ ./essentials.jl:816 [inlined]\n",
      "  [8] (::VSCodeServer.var\"#217#218\"{VSCodeServer.NotebookRunCellArguments, String})()\n",
      "    @ VSCodeServer ~/.vscode-remote/extensions/julialang.language-julia-1.149.2/scripts/packages/VSCodeServer/src/serve_notebook.jl:24\n",
      "  [9] withpath(f::VSCodeServer.var\"#217#218\"{VSCodeServer.NotebookRunCellArguments, String}, path::String)\n",
      "    @ VSCodeServer ~/.vscode-remote/extensions/julialang.language-julia-1.149.2/scripts/packages/VSCodeServer/src/repl.jl:276\n",
      " [10] notebook_runcell_request(conn::VSCodeServer.JSONRPC.JSONRPCEndpoint{Base.PipeEndpoint, Base.PipeEndpoint, VSCodeServer.JSON.Serializations.StandardSerialization}, params::VSCodeServer.NotebookRunCellArguments, token::VSCodeServer.CancellationTokens.CancellationToken)\n",
      "    @ VSCodeServer ~/.vscode-remote/extensions/julialang.language-julia-1.149.2/scripts/packages/VSCodeServer/src/serve_notebook.jl:13\n",
      " [11] dispatch_msg(x::VSCodeServer.JSONRPC.JSONRPCEndpoint{Base.PipeEndpoint, Base.PipeEndpoint, VSCodeServer.JSON.Serializations.StandardSerialization}, dispatcher::VSCodeServer.JSONRPC.MsgDispatcher, msg::VSCodeServer.JSONRPC.Request)\n",
      "    @ VSCodeServer.JSONRPC ~/.vscode-remote/extensions/julialang.language-julia-1.149.2/scripts/packages/JSONRPC/src/typed.jl:68\n",
      " [12] serve_notebook(pipename::String, debugger_pipename::String, outputchannel_logger::Base.CoreLogging.SimpleLogger; error_handler::var\"#7#12\"{String})\n",
      "    @ VSCodeServer ~/.vscode-remote/extensions/julialang.language-julia-1.149.2/scripts/packages/VSCodeServer/src/serve_notebook.jl:147\n",
      " [13] top-level scope\n",
      "    @ ~/.vscode-remote/extensions/julialang.language-julia-1.149.2/scripts/notebook/notebook.jl:35"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import numpy.matlib\n",
    "from mhkit import wave\n",
    "import pandas as pd\n",
    "import os\n",
    "import yaml\n",
    "import re\n",
    "from pathlib import Path\n",
    "from scipy.special import hankel1 as Hankel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-26T14:53:38.713185Z",
     "iopub.status.busy": "2025-07-26T14:53:38.712763Z",
     "iopub.status.idle": "2025-07-26T14:53:38.716050Z",
     "shell.execute_reply": "2025-07-26T14:53:38.715702Z"
    }
   },
   "outputs": [],
   "source": [
    "# Determine root_dir\n",
    "if \"__file__\" in globals():\n",
    "    # Running as a script\n",
    "    script_dir = os.path.dirname(os.path.abspath(__file__))\n",
    "else:\n",
    "    script_dir = os.getcwd()\n",
    "\n",
    "# Traverse up to WEC-DECIDER root\n",
    "root_dir = os.path.abspath(os.path.join(script_dir, \"..\", \"..\"))  \n",
    "cem_dir = os.path.join(root_dir, \"modules\", \"CEM\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-26T14:53:38.717572Z",
     "iopub.status.busy": "2025-07-26T14:53:38.717382Z",
     "iopub.status.idle": "2025-07-26T14:53:38.730306Z",
     "shell.execute_reply": "2025-07-26T14:53:38.729980Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "data_type = '3-hour'\n",
    "year = [2010]\n",
    "parameters = [\n",
    "    'omni-directional_wave_power',\n",
    "    'significant_wave_height',\n",
    "    'energy_period',\n",
    "    'directionality_coefficient',\n",
    "    'maximum_energy_direction',\n",
    "    'mean_absolute_period',\n",
    "    'mean_zero-crossing_period',\n",
    "    'peak_period',\n",
    "    'spectral_width'\n",
    "]\n",
    "lat_lon = (43.5, -70) # off coast of Maine\n",
    "data, metadata = wave.io.hindcast.hindcast.request_wpto_point_data(data_type, parameters, lat_lon, year)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-26T14:53:38.755569Z",
     "iopub.status.busy": "2025-07-26T14:53:38.755252Z",
     "iopub.status.idle": "2025-07-26T14:53:38.775591Z",
     "shell.execute_reply": "2025-07-26T14:53:38.775044Z"
    }
   },
   "outputs": [],
   "source": [
    "data_mod = data.copy()\n",
    "\n",
    "rho_w = 1025  # kg/m^3, density of water\n",
    "g = 9.81  # m/s^2, acceleration due to gravity\n",
    "#J_calc = data_mod[\"significant_wave_height_0\"]**2 * rho_w * g**2 / (64 * np.pi) * data_mod[\"energy_period_0\"]\n",
    "J_calc = data_mod[\"significant_wave_height_0\"]**2 * rho_w * g**2 / (64 * np.pi) * data_mod[\"mean_zero-crossing_period_0\"]\n",
    "fudge = 1 - .007 * (data_mod[\"mean_zero-crossing_period_0\"] - (2*np.pi)) \n",
    "data_mod[\"Power_density_predicted\"] = J_calc / fudge #/ data_mod[\"spectral_width_0\"] #* data_mod[\"directionality_coefficient_0\"]\n",
    "data_mod[\"ratio_power_density\"] = data_mod[\"omni-directional_wave_power_0\"] / data_mod[\"Power_density_predicted\"]\n",
    "\n",
    "data_mod.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-26T14:53:38.778401Z",
     "iopub.status.busy": "2025-07-26T14:53:38.778172Z",
     "iopub.status.idle": "2025-07-26T14:53:39.630425Z",
     "shell.execute_reply": "2025-07-26T14:53:39.630006Z"
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, parameters.__len__(), sharey=True, figsize=(25, 4))\n",
    "units = [\"W/m^2\", \"m\", \"s\", \"-\", \"deg\", \"s\", \"s\", \"s\", \"-\"]\n",
    "for i in range(parameters.__len__()):\n",
    "    col = parameters[i] + \"_0\"\n",
    "    if False: #\"period\" in col and col != \"energy_period_0\":\n",
    "        normalize = True\n",
    "        norm = data_mod[\"energy_period_0\"]\n",
    "    else:\n",
    "        norm = 1\n",
    "        normalize = False\n",
    "    x_data = data_mod[col] / norm\n",
    "    ax[i].scatter(x_data, 1/data_mod[\"ratio_power_density\"])\n",
    "    label = parameters[i] + \" (\" + units[i] + \")\"\n",
    "    if normalize:\n",
    "        label += \" / \" + \"energy_period\" + \" (s)\"\n",
    "    ax[i].set_xlabel(label)\n",
    "    ax[i].plot([x_data.min(), x_data.max()], [1, 1], color='k')\n",
    "ax[0].set_ylabel(\"J calc / J \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-26T14:53:39.632761Z",
     "iopub.status.busy": "2025-07-26T14:53:39.632534Z",
     "iopub.status.idle": "2025-07-26T14:53:39.638812Z",
     "shell.execute_reply": "2025-07-26T14:53:39.638450Z"
    }
   },
   "outputs": [],
   "source": [
    "# capture width\n",
    "G = 1 # gain for heave (=2 for surge/pitch)\n",
    "omega = 2 * np.pi / data_mod[\"mean_zero-crossing_period_0\"]\n",
    "\n",
    "zeta_range = [0.05, 0.15, 0.25]#[0.01, 0.05, 0.1, 0.2, 1]\n",
    "omega_n_range = [0.5, 0.6, 0.7]#[0.4, 0.5, 0.6, 0.7, 1.5]\n",
    "float_diam_range = [20] #[5, 15, 25, 35]  # in meters\n",
    "\n",
    "ZETA, OMEGA, OMEGA_N, D_f = np.meshgrid(zeta_range, omega, omega_n_range, float_diam_range)\n",
    "\n",
    "h = 85 # water depth in meters\n",
    "k = wave.resource.wave_number(omega/ (2*np.pi), h)  # wave number\n",
    "_,K,_,_ = np.meshgrid(zeta_range, k, omega_n_range, float_diam_range) # wave number mesh, to mimic omega mesh\n",
    "mag_B_0_e_nondim = -0.0898 * K + 0.0217 # see fit in MDOcean/dev/B_0_e_vs_frequency.m\n",
    "mag_B_0_e = mag_B_0_e_nondim * h \n",
    "\n",
    "denom = np.cosh(K*h) * np.abs(Hankel(0,K*D_f/2))\n",
    "N_0 = 1 / 2 * (1 + np.sinh(2 * K * h) / (2 * K * h))\n",
    "mag_F_over_eta = 4 * rho_w * g * h * N_0**(1/2) * mag_B_0_e / denom\n",
    "curly_D = np.tanh(K*h) + K*h*(1 - np.tanh(K*h)**2)\n",
    "B_h = mag_F_over_eta**2 / (2 * rho_w * g**2) * K * OMEGA / curly_D\n",
    "B_u = B_h\n",
    "CW_max = G * g / OMEGA**2 # radiation limit\n",
    "\n",
    "real = 1 - (OMEGA / OMEGA_N)**2\n",
    "imag = 2 * ZETA * OMEGA / OMEGA_N\n",
    "mag_RAO_sq = 1/( real**2 + imag**2 )\n",
    "CW_frac_raw = 2 * B_u * OMEGA**5 * mag_RAO_sq / (G * g**3 * rho_w)\n",
    "CW_frac = np.minimum(CW_frac_raw, 1)\n",
    "CW = CW_frac * CW_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-26T14:53:39.640627Z",
     "iopub.status.busy": "2025-07-26T14:53:39.640427Z",
     "iopub.status.idle": "2025-07-26T14:53:40.450444Z",
     "shell.execute_reply": "2025-07-26T14:53:40.449831Z"
    }
   },
   "outputs": [],
   "source": [
    "# bode plot to check mag RAO\n",
    "\n",
    "for d_idx in range(len(float_diam_range)):\n",
    "    fig, ax = plt.subplots()\n",
    "    for z_idx in range(len(zeta_range)):\n",
    "        for o_idx in range(len(omega_n_range)):\n",
    "        \n",
    "            x_data = OMEGA[:, z_idx, o_idx, d_idx]\n",
    "            y_data = 20 * np.log10(np.sqrt(mag_RAO_sq[:, z_idx, o_idx, d_idx]))\n",
    "            sorted_indices = np.argsort(x_data)\n",
    "            x_data = x_data[sorted_indices]\n",
    "            y_data = y_data[sorted_indices]\n",
    "            ax.semilogx(x_data, y_data, label=\"$\\zeta =$ \" + str(zeta_range[z_idx]) + \", $\\omega_n =$ \" + str(omega_n_range[o_idx]))\n",
    "    ax.set_xlabel(\"Frequency (rad/s)\")\n",
    "    ax.set_ylabel(\"Magnitude (dB)\")\n",
    "    ax.set_title(\"Bode plot for float diameter = \" + str(float_diam_range[d_idx]) + \" m\")\n",
    "    ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-26T14:53:40.453800Z",
     "iopub.status.busy": "2025-07-26T14:53:40.453546Z",
     "iopub.status.idle": "2025-07-26T14:53:41.425036Z",
     "shell.execute_reply": "2025-07-26T14:53:41.424288Z"
    }
   },
   "outputs": [],
   "source": [
    "# plot time series of CW fraction\n",
    "for d_idx in range(len(float_diam_range)):\n",
    "    fig, ax = plt.subplots(len(zeta_range), len(omega_n_range), sharey=True, figsize=(10,8))\n",
    "    for z_idx in range(len(zeta_range)):\n",
    "        for o_idx in range(len(omega_n_range)):\n",
    "            # deal with axes size for scalars\n",
    "            if len(zeta_range) == 1 and len(omega_n_range) == 1:\n",
    "                ax_obj = ax\n",
    "            elif len(zeta_range) == 1:\n",
    "                ax_obj = ax[o_idx]\n",
    "            elif len(omega_n_range) == 1:\n",
    "                ax_obj = ax[z_idx]\n",
    "            else:\n",
    "                ax_obj = ax[z_idx, o_idx]\n",
    "\n",
    "            ax_obj.plot(CW_frac_raw[:, z_idx, o_idx])\n",
    "            ax_obj.plot([0, len(CW_frac_raw[:, z_idx, o_idx])], [1, 1], 'k')\n",
    "            if z_idx == 0:\n",
    "                ax_obj.set_title(\"$\\omega_n =$ \" + str(omega_n_range[o_idx]))\n",
    "            if o_idx == 0:\n",
    "                ax_obj.set_ylabel(\"$\\zeta =$ \" + str(zeta_range[z_idx]))\n",
    "            ax_obj.set_ylim([0, 1.5])\n",
    "    fig.supxlabel(\"time index (3-hour intervals)\")\n",
    "    fig.supylabel(\"Raw CW fraction for $D_f =$ \" + str(float_diam_range[d_idx]) + \" m\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-26T14:53:41.431607Z",
     "iopub.status.busy": "2025-07-26T14:53:41.430977Z",
     "iopub.status.idle": "2025-07-26T14:53:41.578414Z",
     "shell.execute_reply": "2025-07-26T14:53:41.577839Z"
    }
   },
   "outputs": [],
   "source": [
    "# Apply different power limits for each zeta and omega_n\n",
    "P_lim_list = np.concatenate( (np.linspace(0.005, 0.025, num=5), np.linspace(0.03, 0.09, num=7), np.linspace(0.1,0.9,num=9)) )\n",
    "\n",
    "for d_idx in range(len(float_diam_range)):\n",
    "    for z_idx in range(len(zeta_range)):\n",
    "        for o_idx in range(len(omega_n_range)):\n",
    "            key_unlimited = \"Avail_zeta_\" + str(zeta_range[z_idx]) + \\\n",
    "                            \"_omega_n_\"   + str(omega_n_range[o_idx]) + \\\n",
    "                            \"_D_f_\"       + str(float_diam_range[d_idx])\n",
    "            data_unlimited = CW_frac[:, z_idx, o_idx, d_idx] / np.max(CW_frac[:, z_idx, o_idx, d_idx])\n",
    "            for P_limit in P_lim_list:\n",
    "                key_limited = key_unlimited + \"_limited_\" + str(int(P_limit*1000))\n",
    "                data_mod[key_limited] = np.minimum(data_unlimited, P_limit) / P_limit\n",
    "            data_mod[key_unlimited] = data_unlimited\n",
    "\n",
    "data_mod = data_mod.copy() # unfragment dataframe\n",
    "pd.set_option('display.max_rows', None)\n",
    "means = data_mod.mean()\n",
    "num_cols_added = 2\n",
    "CFs = np.array(means)[(len(parameters)+num_cols_added):]\n",
    "print(means)\n",
    "print(\"Capacity factors: \",CFs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-26T14:53:41.582296Z",
     "iopub.status.busy": "2025-07-26T14:53:41.581513Z",
     "iopub.status.idle": "2025-07-26T14:53:41.831294Z",
     "shell.execute_reply": "2025-07-26T14:53:41.830864Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "P_lim_list_full = np.concatenate((P_lim_list,[1]))\n",
    "lens = (len(P_lim_list_full),len(zeta_range), len(omega_n_range))\n",
    "P_lim_frac = np.broadcast_to(P_lim_list_full[:,None,None], lens)\n",
    "CF_matrix = np.reshape(CFs, (lens[1],lens[2],lens[0])).transpose(2, 0, 1)\n",
    "\n",
    "cols = ['r','b','g']\n",
    "lines = ['-', '--', ':']\n",
    "fig, ax = plt.subplots()\n",
    "for z_idx in range(len(zeta_range)):\n",
    "    for o_idx in range(len(omega_n_range)):\n",
    "        ax.plot(P_lim_frac[:, z_idx, o_idx], CF_matrix[:, z_idx, o_idx], color=cols[z_idx], linestyle=lines[o_idx],\n",
    "                label=\"$\\zeta =$ \" + str(zeta_range[z_idx]) + \", $\\omega_n =$ \" + str(omega_n_range[o_idx]))\n",
    "ax.set_ylabel('Capacity Factor')\n",
    "ax.set_xlabel('Power Limit Fraction')\n",
    "\n",
    "ax.legend(loc='lower center', bbox_to_anchor=(0.5, 1.05),\n",
    "          ncol=3, fancybox=True, shadow=True)\n",
    "ax.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-26T14:53:41.835132Z",
     "iopub.status.busy": "2025-07-26T14:53:41.834908Z",
     "iopub.status.idle": "2025-07-26T14:53:41.838296Z",
     "shell.execute_reply": "2025-07-26T14:53:41.837936Z"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "fig, ax = plt.subplots()\n",
    "plt.hist(data_mod.Avail, bins=200, density=True)\n",
    "plt.xlabel('Normalized Power')\n",
    "plt.ylabel('Probability Density')\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "plt.hist(data_mod.Avail, bins=200, density=True)\n",
    "plt.plot([0.02, 0.02],[0,12],'k--', [0.04,0.04],[0,4.5],'k--', [0.06,0.06],[0,2.2],'k--',\n",
    "          [0.08,0.08],[0,1.5],'k--', [0.1,0.1],[0,1.5],'k--')\n",
    "plt.xlim([0,0.12])\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-26T14:53:41.840569Z",
     "iopub.status.busy": "2025-07-26T14:53:41.840123Z",
     "iopub.status.idle": "2025-07-26T14:53:41.846220Z",
     "shell.execute_reply": "2025-07-26T14:53:41.845746Z"
    }
   },
   "outputs": [],
   "source": [
    "cap_costs = 1e3 * np.array([400, 500, 600])# 2000, 8500, 15000]) # USD/MW. Wind is around 1e3 * 1,600, nominal RM3 is around 1e3 * 13,000\n",
    "years = [2030,2045]\n",
    "P_lims = np.array([0.1, 0.4, 0.7, 1.0])\n",
    "\n",
    "cap_cost_mesh, year_mesh = np.meshgrid(cap_costs, years)\n",
    "cap_cost_vec = cap_cost_mesh.flatten()\n",
    "year_vec = year_mesh.flatten()\n",
    "\n",
    "print(cap_cost_vec)\n",
    "print(year_vec)\n",
    "\n",
    "wave_cost_str = [f\"Wave_{cap_cost/1e3:.0f}\" for cap_cost in cap_costs] # $k/MW\n",
    "print(wave_cost_str)\n",
    "wave_cost_str_repeated = np.matlib.repmat(wave_cost_str, len(years), 1).flatten()\n",
    "\n",
    "print(wave_cost_str_repeated)\n",
    "\n",
    "#P_lim_string = (P_lim_vec*1000).astype(int).astype(str)\n",
    "#keys = np.char.add( np.repeat(\"Avail_limited_\",np.size(P_lim_vec)), P_lim_string )\n",
    "#print(keys)\n",
    "\n",
    "# use CF to lookup power limit and corresponding availability timeseries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-26T14:53:41.848272Z",
     "iopub.status.busy": "2025-07-26T14:53:41.847946Z",
     "iopub.status.idle": "2025-07-26T14:53:48.319061Z",
     "shell.execute_reply": "2025-07-26T14:53:48.318497Z"
    }
   },
   "outputs": [],
   "source": [
    "# make a separate csv per profile\n",
    "variability_names = []\n",
    "location_folder = cem_dir + '/data_east/'\n",
    "profile_folder = location_folder + 'wave_profiles/'\n",
    "if not os.path.exists(profile_folder):\n",
    "    os.makedirs(profile_folder)\n",
    "\n",
    "csv_num = 0\n",
    "\n",
    "for d_idx in range(len(float_diam_range)):\n",
    "    for P_limit in P_lims:\n",
    "        for z_idx in range(len(zeta_range)):\n",
    "            for o_idx in range(len(omega_n_range)):\n",
    "                key_unlimited = \"Avail_zeta_\" + str(zeta_range[z_idx]) + \"_omega_n_\" + str(omega_n_range[o_idx]) + \"_D_f_\" + str(float_diam_range[d_idx])\n",
    "                key_limited = key_unlimited + \"_limited_\" + str(int(P_limit*1000))\n",
    "                if P_limit == 1:\n",
    "                    key = key_unlimited\n",
    "                else:\n",
    "                    key = key_limited\n",
    "                profile_data = data_mod[key].values\n",
    "                profile_hourly = np.interp(np.arange(0, 8760), np.arange(0, 8760, 3), profile_data)\n",
    "\n",
    "                csv_data = pd.DataFrame()\n",
    "                csv_data[\"technology\"] = wave_cost_str_repeated\n",
    "                csv_data[\"planning_year\"] = year_vec\n",
    "                csv_data[\"capex_mw\"] = cap_cost_vec\n",
    "                csv_data[\"capex_mwh\"] = 0\n",
    "                csv_data[\"fixed_o_m_mw\"] = cap_cost_vec / 10\n",
    "                csv_data[\"fixed_o_m_mwh\"] = 0\n",
    "                csv_data[\"variable_o_m_mwh\"] = 0\n",
    "                csv_data[\"wacc_real\"] = 0.07\n",
    "                csv_data[\"dollar_year\"] = 2014\n",
    "                csv_data[\"heat_rate\"] = 0\n",
    "                csv_data[\"profile\"] = np.array2string(profile_hourly, separator=',', precision=4, threshold=np.inf)\n",
    "\n",
    "                csv_data.to_csv(profile_folder + key_limited +'.csv',index=False)\n",
    "                variability_names.append(key_limited)\n",
    "                csv_num += 1\n",
    "                print(f\"Wrote profile csv {csv_num} of {len(float_diam_range) * len(P_lims) * len(zeta_range) * len(omega_n_range)}\")\n",
    "\n",
    "csv_data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-26T14:53:48.322072Z",
     "iopub.status.busy": "2025-07-26T14:53:48.321817Z",
     "iopub.status.idle": "2025-07-26T14:53:48.331960Z",
     "shell.execute_reply": "2025-07-26T14:53:48.331428Z"
    }
   },
   "outputs": [],
   "source": [
    "# make a scenario inputs csv\n",
    "\n",
    "# grid scenarios (2 dof, 3 options each): electrification, carbon_constraint\n",
    "# year (1 dof, 2 options)\n",
    "# design scenarios (2 dof capturing 4 dof, with 3, 4, 5, and 3 options): wave variability (zeta, omega_n, and power limit), wave cost\n",
    "\n",
    "# total 9 grid scenarios, 2 years, 180 design scenarios = 3240 scenario rows\n",
    "\n",
    "electrification = ['ref','med','high']\n",
    "carbon_constraint = ['low','med','high']\n",
    "scenario_vals = (electrification, carbon_constraint, variability_names, wave_cost_str) # all possible values, for yaml\n",
    "\n",
    "# values to use in this sweep\n",
    "indices_in_use = [[0],[1],range(len(variability_names)),range(len(wave_cost_str))]\n",
    "#indices_in_use = [[0],[1],[0],range(len(wave_cost_str))] # single variability\n",
    "idx_years_used = 0\n",
    "scenario_vals_used = tuple(\n",
    "    [[scenario_vals[i][idx] for idx in idx_list] for i, idx_list in enumerate(indices_in_use)]\n",
    ")\n",
    "scenario_mesh_tuple = np.meshgrid(years[idx_years_used], *scenario_vals_used, indexing='ij')\n",
    "\n",
    "scenario_col_names = ['year', 'electrification', 'carbon_constraint', 'wave_variability', 'wave_cost']\n",
    "\n",
    "scenario_inputs = pd.DataFrame()\n",
    "num_scenarios = len(scenario_mesh_tuple[0].flatten())\n",
    "\n",
    "\n",
    "\n",
    "scenario_inputs[scenario_col_names] = np.array([scenario_col.flatten() for scenario_col in scenario_mesh_tuple]).T\n",
    "\n",
    "#scenario_inputs[\"case_id\"] = ['Case_' + str(i) for i in np.arange(1, num_scenarios + 1)]\n",
    "scenario_inputs[\"case_id\"] = ['Case_' + str('_'.join(str(k) + '_' + str(v) for k, v in row.items())) for row in scenario_inputs.to_dict('records')]\n",
    "\n",
    "print(len(scenario_inputs))\n",
    "scenario_inputs.head()\n",
    "scenario_inputs.to_csv(location_folder + 'scenario_input.csv',index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-26T14:53:48.334679Z",
     "iopub.status.busy": "2025-07-26T14:53:48.334457Z",
     "iopub.status.idle": "2025-07-26T14:53:48.353610Z",
     "shell.execute_reply": "2025-07-26T14:53:48.353268Z"
    }
   },
   "outputs": [],
   "source": [
    "# make a settings management for power genome\n",
    "\n",
    "pg_settings_names = ['electrification_scenario', 'emission_policies_fn', 'additional_technologies_fn', 'additional_new_gen']\n",
    "\n",
    "elec_val_names = ['REFERENCE ELECTRIFICATION - MODERATE TECHNOLOGY ADVANCEMENT', 'MEDIUM ELECTRIFICATION - MODERATE TECHNOLOGY ADVANCEMENT', 'HIGH ELECTRIFICATION - MODERATE TECHNOLOGY ADVANCEMENT']\n",
    "carbon_val_names = ['emission_policies_net_zero.csv','emission_policies.csv','emission_policies_no_limit.csv']\n",
    "wave_var_names = ['wave_profiles/' + key + '.csv' for key in variability_names]\n",
    "wave_cost_val_names = [[str] for str in wave_cost_str] # turn list of strs into list of lists\n",
    "\n",
    "pg_val_names = [elec_val_names, carbon_val_names, wave_var_names, wave_cost_val_names]\n",
    "\n",
    "idxs = range(len(scenario_col_names)-1)\n",
    "scenario_inner_dicts = [dict(zip(scenario_vals[i], \\\n",
    "                               [{pg_settings_names[i]:val} for val in pg_val_names[i]] \\\n",
    "                             )) for i in idxs]\n",
    "scenario_dict = dict(zip(scenario_col_names[1:], scenario_inner_dicts))\n",
    "settings_management = {'settings_management': {year: scenario_dict for year in years}}\n",
    "\n",
    "print(f\"scenario inner dicts: {scenario_inner_dicts}\")\n",
    "print(f\"scenario dict: {scenario_dict}\")\n",
    "print(f\"settings management: {settings_management}\")\n",
    "\n",
    "with open(location_folder + 'settings/settings_management.yml', 'w') as f:\n",
    "    yaml.dump(settings_management, f, sort_keys=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-26T14:53:48.355292Z",
     "iopub.status.busy": "2025-07-26T14:53:48.355095Z",
     "iopub.status.idle": "2025-07-26T14:53:48.360142Z",
     "shell.execute_reply": "2025-07-26T14:53:48.359808Z"
    }
   },
   "outputs": [],
   "source": [
    "# make a cost multiplier yaml for power genome\n",
    "def update_cost_mult_yaml(yaml_file_path, new_yaml_path, anchor_name=\"offshore_wind\"):\n",
    "    \"\"\"\n",
    "    Update the YAML file with new offshore wind technologies.\n",
    "    \n",
    "    Args:\n",
    "        yaml_file_path (str or Path): Path to the YAML file\n",
    "        new_yaml_path (str or Path): Path to save the updated YAML file\n",
    "        anchor_name (str): Name of the YAML anchor to update\n",
    "    \"\"\"\n",
    "    yaml_file_path = Path(yaml_file_path)\n",
    "    new_yaml_path = Path(new_yaml_path)\n",
    "    \n",
    "    # Generate the new offshore wind list\n",
    "    offshore_wind_list = [\"OffShoreWind_Class3\"] + wave_cost_str\n",
    "    print(f\"Generated offshore wind list: {offshore_wind_list}\")\n",
    "    \n",
    "    # Read the current file\n",
    "    with open(yaml_file_path, 'r') as f:\n",
    "        content = f.read()\n",
    "    \n",
    "    print(f\"Original file size: {len(content)} characters\")\n",
    "    print(f\"Looking for anchor: {anchor_name}\")\n",
    "    \n",
    "    # Check if the anchor exists in the file\n",
    "    anchor_pattern = f'{anchor_name}: &{anchor_name}'\n",
    "    if anchor_pattern not in content:\n",
    "        print(f\"Warning: Anchor '{anchor_pattern}' not found in file!\")\n",
    "        print(\"Available content preview:\")\n",
    "        print(content[:500] + \"...\" if len(content) > 500 else content)\n",
    "        return\n",
    "    \n",
    "    # Improved pattern to match the offshore wind anchor section\n",
    "    # This matches from the anchor definition to the end of the list\n",
    "    pattern = rf'({anchor_name}: &{anchor_name}\\n)(.*?)(?=\\n\\S|\\n*$)' \n",
    "    \n",
    "    # Create the new YAML section\n",
    "    new_section = f\"{anchor_name}: &{anchor_name}\\n\"\n",
    "    for tech in offshore_wind_list:\n",
    "        new_section += f\"  - {tech}\\n\"\n",
    "    \n",
    "    print(f\"New section to insert:\\n{new_section}\")\n",
    "    \n",
    "    # Replace the section\n",
    "    new_content = re.sub(pattern, new_section.rstrip() + '\\n', content, flags=re.DOTALL)\n",
    "    \n",
    "    # Write back to file\n",
    "    with open(new_yaml_path, 'w') as f:\n",
    "        f.write(new_content)\n",
    "\n",
    "update_cost_mult_yaml(cem_dir + '/template/cost_mult_tech_map.yml', location_folder + '/settings/cost_mult_tech_map_updated.yml')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "using Pkg\n",
    "Pkg.activate(\"GenX\")\n",
    "]\n",
    "include(\"caserunner.jl\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.9.4",
   "language": "julia",
   "name": "julia-1.9"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
